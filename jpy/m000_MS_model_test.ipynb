{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-02 14:05:37,994 utils 345 [INFO]    [logger_func] start \n",
      "100%|██████████| 3/3 [00:00<00:00,  9.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8921483, 37) (7853253, 37)\n",
      "Categorical: ['f000_EngineVersion', 'f000_Platform', 'f000_ProductName', 'f000_SkuEdition', 'f000_SmartScreen', 'f000_PuaMode', 'f000_OsVer', 'f000_AvSigVersion', 'f000_OsPlatformSubRelease', 'f000_AppVersion', 'f000_Processor', 'f000_OsBuildLab']\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#========================================================================\n",
    "# original library \n",
    "HOME = os.path.expanduser('~')\n",
    "sys.path.append(f\"{HOME}/kaggle/data_analysis/library/\")\n",
    "sys.path.append(f\"{HOME}/kaggle/data_analysis/model/\")\n",
    "from params_MS import params_lgb\n",
    "import utils, ml_utils\n",
    "from utils import logger_func\n",
    "try:\n",
    "    if not logger:\n",
    "        logger=logger_func()\n",
    "except NameError:\n",
    "    logger=logger_func()\n",
    "#========================================================================\n",
    "\n",
    "# Columns\n",
    "key = 'MachineIdentifier'\n",
    "target = 'HasDetections'\n",
    "ignore_list = [key, target]\n",
    "\n",
    "# Basic Args\n",
    "seed = 1208\n",
    "set_type = 'all'\n",
    "\n",
    "\n",
    "feat_path_list = glob.glob('../features/4_winner/*.gz')\n",
    "\n",
    "if sys.argv[1]=='5_tmp':\n",
    "    feat_path_list += glob.glob('../features/5_tmp/*.gz')\n",
    "train, test = ml_utils.get_train_test(feat_path_list=feat_path_list, target=target)\n",
    "print(train.shape, test.shape)\n",
    "\n",
    "is_debug = 1\n",
    "if is_debug:\n",
    "    train = train.head(10000)\n",
    "    test = test.head(500)\n",
    "\n",
    "#========================================================================\n",
    "# Categorical Encode\n",
    "cat_cols = utils.get_categorical_features(df=train, ignore_list=ignore_list)\n",
    "print(f\"Categorical: {cat_cols}\")\n",
    "\n",
    "#Fit LabelEncoder\n",
    "for col in cat_cols:\n",
    "    # 最も頻度の多いカテゴリでimpute\n",
    "    max_freq = list(train[col].value_counts().index)[0]\n",
    "    train[col].fillna(max_freq, inplace=True)\n",
    "    test[col].fillna(max_freq, inplace=True)\n",
    "    le = LabelEncoder().fit(pd.concat([train[col], test[col]], axis=0).value_counts().index.tolist())\n",
    "    train[col] = le.transform(train[col])\n",
    "    test[col]  = le.transform(test[col])\n",
    "#========================================================================\n",
    "\n",
    "Y = train[target]\n",
    "kfold = ml_utils.get_kfold(fold_n=5, fold_type='stratified', seed=seed, train=train, Y=Y)\n",
    "\n",
    "model_type = 'lgr'\n",
    "model_type_list = ['lgb', 'rmf', 'lgr']\n",
    "model_type_list = ['lgb']\n",
    "metric = 'auc'\n",
    "\n",
    "feim_list = []\n",
    "score_list = []\n",
    "oof_pred = np.zeros(len(train))\n",
    "y_test = np.zeros(len(test))\n",
    "\n",
    "use_cols = [col for col in train.columns if col not in ignore_list]\n",
    "x_test = test[use_cols]\n",
    "start_time = \"{0:%Y%m%d_%H%M%S}\".format(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-02 14:07:28,236 utils 6 [INFO]    [<module>] lgb Train Start!! \n",
      "2019-03-02 14:07:28,241 utils 12 [INFO]    [<module>] Fold0 | Train:(8000, 35) | Valid:(2000, 35) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 150 rounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-02 14:07:29,130 utils 27 [INFO]    [<module>] Fold0 CV: 0.6766546654665466 \n",
      "2019-03-02 14:07:29,137 utils 12 [INFO]    [<module>] Fold1 | Train:(8000, 35) | Valid:(2000, 35) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's binary_logloss: 0.649924\n",
      "Early stopping, best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.640491\n",
      "\n",
      "    Model: lgb\n",
      "    feature: ((8000, 35), (2000, 35))\n",
      "    auc: 0.6766546654665466\n",
      "    \n",
      "Training until validation scores don't improve for 150 rounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-02 14:07:29,935 utils 27 [INFO]    [<module>] Fold1 CV: 0.6507340734073408 \n",
      "2019-03-02 14:07:29,942 utils 12 [INFO]    [<module>] Fold2 | Train:(8000, 35) | Valid:(2000, 35) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's binary_logloss: 0.669419\n",
      "Early stopping, best iteration is:\n",
      "[68]\tvalid_0's binary_logloss: 0.654094\n",
      "\n",
      "    Model: lgb\n",
      "    feature: ((8000, 35), (2000, 35))\n",
      "    auc: 0.6507340734073408\n",
      "    \n",
      "Training until validation scores don't improve for 150 rounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-02 14:07:30,794 utils 27 [INFO]    [<module>] Fold2 CV: 0.662092209220922 \n",
      "2019-03-02 14:07:30,801 utils 12 [INFO]    [<module>] Fold3 | Train:(8000, 35) | Valid:(2000, 35) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's binary_logloss: 0.664506\n",
      "Early stopping, best iteration is:\n",
      "[80]\tvalid_0's binary_logloss: 0.648069\n",
      "\n",
      "    Model: lgb\n",
      "    feature: ((8000, 35), (2000, 35))\n",
      "    auc: 0.662092209220922\n",
      "    \n",
      "Training until validation scores don't improve for 150 rounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-02 14:07:31,538 utils 27 [INFO]    [<module>] Fold3 CV: 0.6377637763776378 \n",
      "2019-03-02 14:07:31,545 utils 12 [INFO]    [<module>] Fold4 | Train:(8000, 35) | Valid:(2000, 35) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's binary_logloss: 0.69199\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's binary_logloss: 0.662805\n",
      "\n",
      "    Model: lgb\n",
      "    feature: ((8000, 35), (2000, 35))\n",
      "    auc: 0.6377637763776378\n",
      "    \n",
      "Training until validation scores don't improve for 150 rounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-02 14:07:32,393 utils 27 [INFO]    [<module>] Fold4 CV: 0.6592794279427944 \n",
      "2019-03-02 14:07:32,398 utils 41 [INFO]    [<module>] \n",
      "    #========================================================================\n",
      "    # Model: lgb\n",
      "    # CV   : 0.6573048304830482\n",
      "    #======================================================================== \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's binary_logloss: 0.663161\n",
      "Early stopping, best iteration is:\n",
      "[80]\tvalid_0's binary_logloss: 0.650674\n",
      "\n",
      "    Model: lgb\n",
      "    feature: ((8000, 35), (2000, 35))\n",
      "    auc: 0.6592794279427944\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "for model_type in model_type_list:\n",
    "    if model_type=='lgb':\n",
    "        params = params_lgb()\n",
    "    else:\n",
    "        params = {}\n",
    "    logger.info(f\"{model_type} Train Start!!\")\n",
    "    \n",
    "    for fold_n, (trn_idx, val_idx) in enumerate(kfold):\n",
    "        x_train, y_train = train[use_cols].iloc[trn_idx, :], Y.iloc[trn_idx]\n",
    "        x_val, y_val = train[use_cols].iloc[val_idx, :], Y.iloc[val_idx]\n",
    "\n",
    "        logger.info(f\"Fold{fold_n} | Train:{x_train.shape} | Valid:{x_val.shape}\")\n",
    "\n",
    "        score, tmp_oof, tmp_pred, feim = ml_utils.Classifier(\n",
    "            model_type=model_type\n",
    "            , x_train=x_train\n",
    "            , y_train=y_train\n",
    "            , x_val=x_val\n",
    "            , y_val=y_val\n",
    "            , x_test=x_test\n",
    "            , params=params\n",
    "            , seed=seed\n",
    "            , get_score=metric\n",
    "        )\n",
    "        feim_list.append(feim.set_index('feature').rename(columns={'importance':f'imp_{fold_n}'}))\n",
    "\n",
    "        logger.info(f\"Fold{fold_n} CV: {score}\")\n",
    "        score_list.append(score)\n",
    "        oof_pred[val_idx] = tmp_oof\n",
    "        y_test += tmp_pred\n",
    "\n",
    "    feim = pd.concat(feim_list, axis=1)\n",
    "    feim_cols = [col for col in feim.columns if col.count('imp_')]\n",
    "    feim['importance'] = feim[feim_cols].mean(axis=1)\n",
    "\n",
    "    cv_score = np.mean(score_list)\n",
    "    logger.info(f'''\n",
    "    #========================================================================\n",
    "    # Model: {model_type}\n",
    "    # CV   : {cv_score}\n",
    "    #========================================================================''')\n",
    "\n",
    "    y_test /= (fold_n+1)\n",
    "\n",
    "    pred_col = 'prediction'\n",
    "    train[pred_col] = oof_pred\n",
    "    test[pred_col] = y_test\n",
    "    stack_cols = [key, target, pred_col]\n",
    "\n",
    "    df_stack = pd.concat([train[stack_cols], test[stack_cols]], ignore_index=True, axis=0)\n",
    "    \n",
    "    #========================================================================\n",
    "    # Saving \n",
    "    feim.to_csv(f'../valid/{start_time[4:12]}_{model_type}_SET-{set_type}_feat{len(x_train.columns)}_CV{str(cv_score)[:7]}.csv', index=True)\n",
    "    utils.to_pkl_gzip(obj=df_stack, path=f'../stack/{start_time[4:12]}_{model_type}_SET-{set_type}_feat{len(x_train.columns)}_CV{str(cv_score)[:7]}')\n",
    "    #========================================================================"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
