{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "HOME = os.path.expanduser('~')\n",
    "sys.path.append(f\"{HOME}/kaggle/data_analysis/library/\")\n",
    "import utils\n",
    "from utils import logger_func\n",
    "try:\n",
    "    if not logger:\n",
    "        logger=logger_func()\n",
    "except NameError:\n",
    "    logger=logger_func()\n",
    "\n",
    "key = 'MachineIdentifier'\n",
    "target = 'HasDetections'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "b130d0c90f9052e4e79d9a42a33126d326f99e76"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../tool/ctrNet-tool/')\n",
    "import ctrNet\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src import misc_utils\n",
    "import os\n",
    "import gc\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# import glob\n",
    "# feat_path_list = glob.glob('../features/4_winner/*.gz')\n",
    "# p_list = utils.parallel_load_data(path_list=feat_path_list)\n",
    "# df_feat = pd.concat(p_list, axis=1)\n",
    "\n",
    "base = utils.read_df_pkl('../input/base_gr*')[[key, target, 'country_group']]\n",
    "base_train = base[~base[target].isnull()]\n",
    "len_train = base_train.shape[0]\n",
    "del p_list, base\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "f24dcd1a223ea1175800f722952980c4a8a4215c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [50:38<00:00, 21.81s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "#========================================================================\n",
    "# Loading Dataset\n",
    "#========================================================================\n",
    "def make_bucket(data,num=10):\n",
    "    data.sort()\n",
    "    bins=[]\n",
    "    for i in range(num):\n",
    "        bins.append(data[int(len(data)*(i+1)//num)-1])\n",
    "    return bins\n",
    "\n",
    "float_features = utils.get_numeric_features(df_feat, ignore_list=[key, target])\n",
    "\n",
    "for f in tqdm(float_features):\n",
    "#     data=list(train[f])+list(test[f])\n",
    "    mode = df_feat[~df_feat[f].isnull()][f].mode()[0]\n",
    "    df_feat[f].fillna(mode, inplace=True)\n",
    "    data = df_feat[f].tolist()\n",
    "    bins=make_bucket(data,num=50)\n",
    "    df_feat[f] = np.digitize(df_feat[f], bins=bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_list = [key, target]\n",
    "cat_cols = utils.get_categorical_features(df_feat, ignore_list=ignore_list)\n",
    "\n",
    "for col in cat_cols:\n",
    "    df_feat[col].fillna(0, inplace=True)\n",
    "\n",
    "train = df_feat.iloc[:len_train, :]\n",
    "test = df_feat.iloc[len_train:, :]\n",
    "features = [col for col in train.columns if col not in ignore_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "40b2ecd8536dcac62d426daeeb8c5f79f8f817c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  activation=['relu', 'relu', 'relu']\n",
      "  batch_norm_decay=0.9\n",
      "  batch_size=1024\n",
      "  cross_activation=identity\n",
      "  cross_layer_sizes=[128, 128, 128]\n",
      "  epoch=1\n",
      "  feature_nums=148\n",
      "  hash_ids=200000\n",
      "  hidden_size=[128, 128]\n",
      "  init_method=uniform\n",
      "  init_value=0.1\n",
      "  k=8\n",
      "  kfold=5\n",
      "  learning_rate=0.001\n",
      "  metric=auc\n",
      "  model=xdeepfm\n",
      "  norm=True\n",
      "  num_display_steps=1000\n",
      "  num_eval_steps=1000\n",
      "  optimizer=adam\n"
     ]
    }
   ],
   "source": [
    "hparam=tf.contrib.training.HParams(\n",
    "            model='xdeepfm',\n",
    "            norm=True,\n",
    "            batch_norm_decay=0.9,\n",
    "            hidden_size=[128,128],\n",
    "            cross_layer_sizes=[128,128,128],\n",
    "            k=8,\n",
    "            hash_ids=int(2e5),\n",
    "            batch_size=1024,\n",
    "            optimizer=\"adam\",\n",
    "            learning_rate=0.001,\n",
    "            num_display_steps=1000,\n",
    "            num_eval_steps=1000,\n",
    "            epoch=1,\n",
    "            metric='auc',\n",
    "            activation=['relu','relu','relu'],\n",
    "            cross_activation='identity',\n",
    "            init_method='uniform',\n",
    "            init_value=0.1,\n",
    "            feature_nums=len(features),\n",
    "            kfold=5)\n",
    "misc_utils.print_hparams(hparam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "66e67bbf4fb72dfb853ca1cb05ce993f670bec35"
   },
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[target] = base_train[target].values\n",
    "test[target] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=set(range(train.shape[0]))\n",
    "K_fold=[]\n",
    "for i in range(hparam.kfold):\n",
    "    if i == hparam.kfold-1:\n",
    "        tmp=index\n",
    "    else:\n",
    "        tmp=random.sample(index,int(1.0/hparam.kfold*train.shape[0]))\n",
    "    index=index-set(tmp)\n",
    "    print(\"Number:\",len(tmp))\n",
    "    K_fold.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6c48b409a4e86c09ca395c3a4f75b2b1c372d124"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "# Trainable variables\n",
      "  emb_v1:0, (200000, 1), \n",
      "  emb_v2:0, (200000, 8), \n",
      "  Variable:0, (1184, 128), \n",
      "  norm_0/beta:0, (128,), \n",
      "  norm_0/gamma:0, (128,), \n",
      "  Variable_1:0, (128, 128), \n",
      "  norm_1/beta:0, (128,), \n",
      "  norm_1/gamma:0, (128,), \n",
      "  Variable_2:0, (128, 1), \n",
      "  exfm_part/f_0:0, (1, 21904, 128), \n",
      "  exfm_part/f_1:0, (1, 9472, 128), \n",
      "  exfm_part/f_2:0, (1, 9472, 128), \n",
      "  exfm_part/w_nn_output:0, (256, 1), \n",
      "  exfm_part/b_nn_output:0, (1,), \n",
      "  epoch 0 step 1000 lr 0.001 logloss 0.619496 gN 0.30, Tue Mar 12 22:13:13 2019\n",
      "# Epcho-time 223.05s Eval AUC 0.721773. Best AUC 0.721773.\n",
      "  epoch 0 step 2000 lr 0.001 logloss 0.605771 gN 0.24, Tue Mar 12 22:17:28 2019\n",
      "# Epcho-time 477.70s Eval AUC 0.729980. Best AUC 0.729980.\n",
      "  epoch 0 step 3000 lr 0.001 logloss 0.602579 gN 0.23, Tue Mar 12 22:21:42 2019\n",
      "# Epcho-time 732.48s Eval AUC 0.732971. Best AUC 0.732971.\n",
      "  epoch 0 step 4000 lr 0.001 logloss 0.600521 gN 0.22, Tue Mar 12 22:25:58 2019\n",
      "# Epcho-time 988.38s Eval AUC 0.734562. Best AUC 0.734562.\n",
      "  epoch 0 step 5000 lr 0.001 logloss 0.598817 gN 0.21, Tue Mar 12 22:30:18 2019\n",
      "# Epcho-time 1248.18s Eval AUC 0.735656. Best AUC 0.735656.\n",
      "  epoch 0 step 6000 lr 0.001 logloss 0.598064 gN 0.21, Tue Mar 12 22:34:35 2019\n",
      "# Epcho-time 1505.22s Eval AUC 0.737564. Best AUC 0.737564.\n",
      "# Epcho-time 1756.73s Eval AUC 0.738002. Best AUC 0.738002.\n",
      "INFO:tensorflow:Restoring parameters from model_tmp/model\n",
      "# Epcho-time 1789.95s Eval AUC 0.737999. Best AUC 0.738002.\n",
      "Training Done! Inference...\n",
      "Fold 1\n",
      "# Trainable variables\n",
      "  emb_v1:0, (200000, 1), \n",
      "  emb_v2:0, (200000, 8), \n",
      "  Variable:0, (1184, 128), \n",
      "  norm_0/beta:0, (128,), \n",
      "  norm_0/gamma:0, (128,), \n",
      "  Variable_1:0, (128, 128), \n",
      "  norm_1/beta:0, (128,), \n",
      "  norm_1/gamma:0, (128,), \n",
      "  Variable_2:0, (128, 1), \n",
      "  exfm_part/f_0:0, (1, 21904, 128), \n",
      "  exfm_part/f_1:0, (1, 9472, 128), \n",
      "  exfm_part/f_2:0, (1, 9472, 128), \n",
      "  exfm_part/w_nn_output:0, (256, 1), \n",
      "  exfm_part/b_nn_output:0, (1,), \n"
     ]
    }
   ],
   "source": [
    "y_pred = np.zeros(train.shape[0])\n",
    "for i in range(hparam.kfold):       \n",
    "        \n",
    "    print(\"Fold\",i)\n",
    "    dev_index=K_fold[i]\n",
    "    dev_index=random.sample(dev_index,int(0.1*len(dev_index)))\n",
    "    train_index=[]\n",
    "    for j in range(hparam.kfold):\n",
    "        if j!=i:\n",
    "            train_index+=K_fold[j]\n",
    "            \n",
    "    x_train = train.iloc[train_index][features]\n",
    "    y_train = train.iloc[train_index]['HasDetections']\n",
    "    x_val = train.iloc[dev_index][features]\n",
    "    y_val = train.iloc[dev_index]['HasDetections']\n",
    "    \n",
    "    model=ctrNet.build_model(hparam)\n",
    "    model.train(train_data=(x_train, y_train), dev_data=(x_val, y_val))\n",
    "    print(\"Training Done! Inference...\")\n",
    "    if i==0:\n",
    "        y_pred[dev_index] += model.infer(dev_data=(x_val, y_val))/hparam.kfold\n",
    "        y_test = model.infer(dev_data=(test[features], test['HasDetections']))/hparam.kfold\n",
    "    else:\n",
    "        y_pred[dev_index] += model.infer(dev_data=(x_val, y_val))/hparam.kfold\n",
    "        y_test += model.infer(dev_data=(test[features],test['HasDetections']))/hparam.kfold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4302884724f2191b363591d5af43c1dc12c79a48"
   },
   "source": [
    "cat_cols = utils.get_categorical_features(df_feat, ignore_list=[key, target])\n",
    "\n",
    "train = df_feat.iloc[:len_train, :]\n",
    "test = df_feat.iloc[len_train:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fcd62d5f09ca9d78e96854d84433325fb80f6096"
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../input/sample_submission.csv')\n",
    "submission['HasDetections'] = preds\n",
    "print(submission['HasDetections'].head())\n",
    "submission.to_csv('nffm_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_1_test = y_test.copy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
