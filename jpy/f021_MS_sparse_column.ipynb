{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-12 22:08:21,538 utils 346 [INFO]    [logger_func] start \n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "HOME = os.path.expanduser('~')\n",
    "sys.path.append(f\"{HOME}/kaggle/data_analysis/library/\")\n",
    "sys.path.append(f\"../py/\")\n",
    "import MS_utils\n",
    "import utils, ml_utils\n",
    "from utils import logger_func\n",
    "try:\n",
    "    if not logger:\n",
    "        logger=logger_func()\n",
    "except NameError:\n",
    "    logger=logger_func()\n",
    "\n",
    "pd.set_option(\"max_columns\", 200)\n",
    "pd.set_option(\"max_rows\", 400)\n",
    "\n",
    "# Columns\n",
    "key, target, ignore_list = MS_utils.get_basic_var()\n",
    "ignore_list = [key, target]\n",
    "\n",
    "# Basic Args\n",
    "seed = 1208\n",
    "set_type = 'all'\n",
    "\n",
    "from scipy.sparse import vstack, csr_matrix, save_npz, load_npz, hstack\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_type_list = [\n",
    "    'ProductName'\n",
    "    ,'EngineVersion'\n",
    "    ,'AppVersion'\n",
    "    ,'AvSigVersion'\n",
    "    ,'DefaultBrowsersIdentifier'\n",
    "    ,'AVProductStatesIdentifier'\n",
    "    ,'AVProductsInstalled'\n",
    "    ,'AVProductsEnabled'\n",
    "    ,'CountryIdentifier'\n",
    "    ,'CityIdentifier'\n",
    "    ,'OrganizationIdentifier'\n",
    "    ,'LocaleEnglishNameIdentifier'\n",
    "    ,'OsBuildLab'\n",
    "    ,'SkuEdition'\n",
    "    ,'IsProtected'\n",
    "    ,'IeVerIdentifier'\n",
    "    ,'SmartScreen'\n",
    "    ,'Firewall'\n",
    "    ,'Census_OEMNameIdentifier'\n",
    "    ,'Census_OEMModelIdentifier'\n",
    "    ,'Census_ProcessorManufacturerIdentifier'\n",
    "    ,'Census_ProcessorModelIdentifier'\n",
    "    ,'Census_PrimaryDiskTypeName'\n",
    "    ,'Census_HasOpticalDiskDrive'\n",
    "    ,'Census_ChassisTypeName'\n",
    "    ,'Census_PowerPlatformRoleName'\n",
    "    ,'Census_InternalBatteryType'\n",
    "    ,'Census_OSVersion'\n",
    "    ,'Census_OSArchitecture'\n",
    "    ,'Census_OSBuildNumber'\n",
    "    ,'Census_OSEdition'\n",
    "    ,'Census_OSSkuName'\n",
    "    ,'Census_OSInstallTypeName'\n",
    "    ,'Census_OSInstallLanguageIdentifier'\n",
    "    ,'Census_OSUILocaleIdentifier'\n",
    "    ,'Census_OSWUAutoUpdateOptionsName'\n",
    "    ,'Census_GenuineStateName'\n",
    "    ,'Census_ActivationChannel'\n",
    "    ,'Census_IsFlightingInternal'\n",
    "    ,'Census_IsFlightsDisabled'\n",
    "    ,'Census_FlightRing'\n",
    "    ,'Census_ThresholdOptIn'\n",
    "    ,'Census_FirmwareManufacturerIdentifier'\n",
    "    ,'Census_FirmwareVersionIdentifier'\n",
    "    ,'Census_IsSecureBootEnabled'\n",
    "    ,'Census_IsWIMBootEnabled'\n",
    "    ,'Census_IsVirtualDevice'\n",
    "    ,'Census_IsTouchEnabled'\n",
    "    ,'Census_IsPenCapable'\n",
    "    ,'Census_IsAlwaysOnAlwaysConnectedCapable'\n",
    "    ,'Wdft_IsGamer'\n",
    "    ,'Wdft_RegionIdentifier'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "Process ForkPoolWorker-8:\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "Process ForkPoolWorker-10:\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Process ForkPoolWorker-7:\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "feat_path_list = glob.glob('../features/4_winner/f*')\n",
    "p_list = utils.parallel_load_data(path_list=feat_path_list)\n",
    "tmp_feat = pd.concat(p_list, axis=1)\n",
    "base = utils.read_df_pkl('../input/base_Av*')[[key, target]]\n",
    "df_feat = pd.concat([base, tmp_feat], axis=1)\n",
    "del p_list, base, tmp_feat\n",
    "gc.collect()\n",
    "\n",
    "len_train = df_feat[~df_feat[target].isnull()].shape[0]\n",
    "df_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/140 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/140 [00:20<47:59, 20.71s/it]\u001b[A\n",
      "  1%|▏         | 2/140 [00:40<47:15, 20.55s/it]\u001b[A\n",
      "  2%|▏         | 3/140 [00:57<44:33, 19.52s/it]\u001b[A\n",
      "  3%|▎         | 4/140 [01:18<45:11, 19.94s/it]\u001b[A\n",
      "  4%|▎         | 5/140 [01:40<46:01, 20.45s/it]\u001b[A\n",
      "  4%|▍         | 6/140 [02:03<47:10, 21.12s/it]\u001b[A\n",
      "  5%|▌         | 7/140 [02:23<46:30, 20.98s/it]\u001b[A\n",
      "  6%|▌         | 8/140 [02:44<46:07, 20.97s/it]\u001b[A\n",
      "  6%|▋         | 9/140 [03:05<45:44, 20.95s/it]\u001b[A\n",
      "  7%|▋         | 10/140 [03:26<45:31, 21.01s/it]\u001b[A\n",
      "  8%|▊         | 11/140 [03:46<44:31, 20.71s/it]\u001b[A\n",
      "  9%|▊         | 12/140 [04:07<43:59, 20.62s/it]\u001b[A\n",
      "  9%|▉         | 13/140 [04:23<40:43, 19.24s/it]\u001b[A\n",
      " 10%|█         | 14/140 [04:43<40:53, 19.47s/it]\u001b[A\n",
      " 11%|█         | 15/140 [05:03<41:13, 19.78s/it]\u001b[A\n",
      " 11%|█▏        | 16/140 [05:24<41:27, 20.06s/it]\u001b[A\n",
      " 12%|█▏        | 17/140 [05:38<37:25, 18.26s/it]\u001b[A\n",
      " 13%|█▎        | 18/140 [05:59<38:54, 19.14s/it]\u001b[A\n",
      " 14%|█▎        | 19/140 [06:20<39:44, 19.71s/it]\u001b[A\n",
      " 14%|█▍        | 20/140 [06:36<37:08, 18.57s/it]\u001b[A\n",
      " 15%|█▌        | 21/140 [06:51<34:47, 17.54s/it]\u001b[A\n",
      " 16%|█▌        | 22/140 [07:14<37:10, 18.91s/it]\u001b[A\n",
      " 16%|█▋        | 23/140 [07:32<36:47, 18.87s/it]\u001b[A\n",
      " 17%|█▋        | 24/140 [07:52<36:57, 19.11s/it]\u001b[A\n",
      " 18%|█▊        | 25/140 [08:11<36:48, 19.20s/it]\u001b[A\n",
      " 19%|█▊        | 26/140 [08:32<37:22, 19.67s/it]\u001b[A\n",
      " 19%|█▉        | 27/140 [08:53<37:28, 19.90s/it]\u001b[A\n",
      " 20%|██        | 28/140 [09:12<37:05, 19.87s/it]\u001b[A\n",
      " 21%|██        | 29/140 [09:30<35:35, 19.24s/it]\u001b[A\n",
      " 21%|██▏       | 30/140 [09:51<36:20, 19.82s/it]\u001b[A\n",
      " 22%|██▏       | 31/140 [10:11<35:49, 19.72s/it]\u001b[A\n",
      " 23%|██▎       | 32/140 [10:25<32:19, 17.96s/it]\u001b[A\n",
      " 24%|██▎       | 33/140 [10:40<30:45, 17.25s/it]\u001b[A\n",
      " 24%|██▍       | 34/140 [11:00<31:39, 17.92s/it]\u001b[A\n",
      " 25%|██▌       | 35/140 [11:19<32:09, 18.38s/it]\u001b[A\n",
      " 26%|██▌       | 36/140 [11:39<32:43, 18.88s/it]\u001b[A\n",
      " 26%|██▋       | 37/140 [11:54<30:17, 17.65s/it]\u001b[A\n",
      " 27%|██▋       | 38/140 [12:12<30:01, 17.66s/it]\u001b[A\n",
      " 28%|██▊       | 39/140 [12:26<27:49, 16.53s/it]\u001b[A\n",
      " 29%|██▊       | 40/140 [12:45<29:01, 17.41s/it]\u001b[A\n",
      " 29%|██▉       | 41/140 [13:08<31:30, 19.10s/it]\u001b[A\n",
      " 30%|███       | 42/140 [13:29<32:05, 19.65s/it]\u001b[A\n",
      " 31%|███       | 43/140 [13:49<31:59, 19.79s/it]\u001b[A\n",
      " 31%|███▏      | 44/140 [14:09<31:44, 19.84s/it]\u001b[A\n",
      " 32%|███▏      | 45/140 [14:29<31:17, 19.77s/it]\u001b[A\n",
      " 33%|███▎      | 46/140 [14:48<30:38, 19.56s/it]\u001b[A\n",
      " 34%|███▎      | 47/140 [15:08<30:33, 19.72s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "train = df_feat.iloc[:len_train]\n",
    "test = df_feat.iloc[len_train:]\n",
    "cat_cols = utils.get_categorical_features(train, ignore_list=[key, target])\n",
    "num_list = utils.get_numeric_features(train, ignore_list)\n",
    "# for usecol in tqdm(cat_cols):\n",
    "for usecol in tqdm(num_list):\n",
    "    if usecol in ignore_list:\n",
    "        continue\n",
    "        \n",
    "    train[usecol] = train[usecol].astype('str')\n",
    "    test[usecol] = test[usecol].astype('str')\n",
    "        \n",
    "    #Fit LabelEncoder\n",
    "    le = LabelEncoder().fit(\n",
    "            np.unique(train[usecol].unique().tolist()+\n",
    "                      test[usecol].unique().tolist()))\n",
    "\n",
    "    #At the end 0 will be used for dropped values\n",
    "    train[usecol] = le.transform(train[usecol])+1\n",
    "    test[usecol]  = le.transform(test[usecol])+1\n",
    "\n",
    "    agg_tr = (train\n",
    "              .groupby([usecol])\n",
    "              .aggregate({'MachineIdentifier':'count'})\n",
    "              .reset_index()\n",
    "              .rename({'MachineIdentifier':'Train'}, axis=1))\n",
    "    agg_te = (test\n",
    "              .groupby([usecol])\n",
    "              .aggregate({'MachineIdentifier':'count'})\n",
    "              .reset_index()\n",
    "              .rename({'MachineIdentifier':'Test'}, axis=1))\n",
    "\n",
    "    agg = pd.merge(agg_tr, agg_te, on=usecol, how='outer').replace(np.nan, 0)\n",
    "    #Select values with more than 1000 observations\n",
    "    agg = agg[(agg['Train'] > 1000)].reset_index(drop=True)\n",
    "    agg['Total'] = agg['Train'] + agg['Test']\n",
    "    #Drop unbalanced values\n",
    "    agg = agg[(agg['Train'] / agg['Total'] > 0.2) & (agg['Train'] / agg['Total'] < 0.8)]\n",
    "    agg[usecol+'Copy'] = agg[usecol]\n",
    "\n",
    "    train[usecol] = (pd.merge(train[[usecol]], \n",
    "                              agg[[usecol, usecol+'Copy']], \n",
    "                              on=usecol, how='left')[usecol+'Copy']\n",
    "                     .replace(np.nan, 0).astype('int').astype('category'))\n",
    "\n",
    "    test[usecol]  = (pd.merge(test[[usecol]], \n",
    "                              agg[[usecol, usecol+'Copy']], \n",
    "                              on=usecol, how='left')[usecol+'Copy']\n",
    "                     .replace(np.nan, 0).astype('int').astype('category'))\n",
    "\n",
    "    del le, agg_tr, agg_te, agg, usecol\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import vstack, csr_matrix, save_npz, load_npz\n",
    "\n",
    "#Fit OneHotEncoder\n",
    "print(\"OHE Fitting...\")\n",
    "ohe = OneHotEncoder(categories='auto', sparse=True, dtype='uint8').fit(train)\n",
    "\n",
    "#Transform data using small groups to reduce memory usage\n",
    "\n",
    "print(\"Encoding Start!!\")\n",
    "m = 100000\n",
    "train = vstack([ohe.transform(train[i*m:(i+1)*m]) for i in range(train.shape[0] // m + 1)])\n",
    "test  = vstack([ohe.transform(test[i*m:(i+1)*m])  for i in range(test.shape[0] // m +  1)])\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Saving...\")\n",
    "save_npz('../input/sp_train.npz', train, compressed=True)\n",
    "save_npz('../input/sp_test.npz',  test,  compressed=True)\n",
    "\n",
    "del ohe, train, test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform data using small groups to reduce memory usage\n",
    "m = 100000\n",
    "train = vstack([ohe.transform(train[i*m:(i+1)*m]) for i in range(train.shape[0] // m + 1)])\n",
    "test  = vstack([ohe.transform(test[i*m:(i+1)*m])  for i in range(test.shape[0] // m +  1)])\n",
    "print(\"Saving...\")\n",
    "save_npz(f'../input/sparse_train_{n_feature}.npz', train, compressed=True)\n",
    "save_npz(f'../input/sparse_test_{n_feature}.npz',  test,  compressed=True)\n",
    "print(\"Complete!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numeric Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_path_list = glob.glob('../features/4_winner/*.gz')\n",
    "p_list = utils.parallel_load_data(path_list=num_path_list)\n",
    "num_feat = pd.concat(p_list, axis=1)\n",
    "base = utils.read_df_pkl('../input/base_Av*')[[key, target]]\n",
    "len_train = base[~base[target].isnull()].shape[0]\n",
    "del p_list\n",
    "gc.collect()\n",
    "num_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_list = num_feat.columns.tolist()\n",
    "len(feat_list)//10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from scipy.sparse import vstack, csr_matrix, save_npz, load_npz, hstack\n",
    "from scipy import sparse\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "#========================================================================\n",
    "# Impute \n",
    "# for col in tqdm(num_feat.columns):\n",
    "def multi_mode(feature, col):\n",
    "#     mode = num_feat[~num_feat[col].isnull()][col].mode()[0]\n",
    "    mode = feature.loc[~feature.isnull()].mode()[0]\n",
    "    return feature.fillna(mode).values\n",
    "    \n",
    "# for i in range(30, 151, 30):\n",
    "for i in [30, 30]:\n",
    "    feat_list = num_feat.columns.tolist()[i-30:i]\n",
    "    p_list += Parallel(n_jobs=-1)([delayed(multi_mode)(num_feat[col], col) for col in feat_list])\n",
    "    num_feat.drop(feat_list, axis=1, inplace=True)\n",
    "    gc.collect()\n",
    "    \n",
    "#========================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================================================\n",
    "# binning Dataset\n",
    "def make_bucket(data,num=10):\n",
    "    data.sort()\n",
    "    bins=[]\n",
    "    for i in range(num):\n",
    "        bins.append(data[int(len(data)*(i+1)//num)-1])\n",
    "    return bins\n",
    "\n",
    "feature_list = []\n",
    "for feature in tqdm(p_list):\n",
    "    bins=make_bucket(feature, num=50)\n",
    "    try:\n",
    "        feature_list.append(np.digitize(feature, bins=bins))\n",
    "    except TypeError:\n",
    "        feature_list.append(feature)\n",
    "#========================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_list = []\n",
    "num_list = []\n",
    "for f in feature_list:\n",
    "    if str(type(f[0])).count('str'):\n",
    "        cat_list.append(f)\n",
    "    else:\n",
    "        num_list.append(f)\n",
    "# Impute してから\n",
    "cat_list = np.asarray(cat_list).T\n",
    "num_list = np.asarray(num_list).T\n",
    "ohe_cat = OneHotEncoder(categories='auto', sparse=True, dtype='uint8').fit(cat_list)\n",
    "ohe_num = OneHotEncoder(categories='auto', sparse=True, dtype='uint8').fit(num_list)\n",
    "\n",
    "del feature_list\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_feature = len(cat_list) + len(num_list)\n",
    "\n",
    "m=100000\n",
    "cat_train = vstack([ohe_cat.transform(cat_list[i*m:(i+1)*m]) for i in range(len(cat_list) // m + 1)])\n",
    "num_train = vstack([ohe_num.transform(num_list[i*m:(i+1)*m]) for i in range(len(num_list) // m + 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_npz(f'../input/sparse_num_row{num_train.shape[0]}_feat{num_train.shape[1]}.npz', num_train, compressed=True)\n",
    "save_npz(f'../input/sparse_cat_row{cat_train.shape[0]}_feat{cat_train.shape[1]}.npz',  cat_train,  compressed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sp_train_1 = load_npz('../input/sparse_train_92.npz')\n",
    "# sp_test_1 = load_npz('../input/sparse_test_92.npz')\n",
    "\n",
    "len_train = sp_train_1.shape[0]\n",
    "\n",
    "sp_2 = load_npz('../input/sparse_num_row16774736_feat2376.npz')\n",
    "sp_train_2 = sp_2[:len_train, :]\n",
    "sp_test_2 = sp_2[len_train:, :]\n",
    "del sp_2\n",
    "gc.collect()\n",
    "\n",
    "sp_3 = load_npz('../input/sparse_cat_row16774736_feat297020.npz')\n",
    "sp_train_3 = sp_3[:len_train, :]\n",
    "sp_test_3 = sp_3[len_train:, :]\n",
    "del sp_3\n",
    "gc.collect()\n",
    "\n",
    "sp_train = hstack([sp_train_1, sp_train_2, sp_train_3])\n",
    "sp_test = hstack([sp_test_1, sp_test_2, sp_test_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8921483, 1845868)\n",
      "(7853253, 1845868)\n"
     ]
    }
   ],
   "source": [
    "print(sp_train.shape)\n",
    "print(sp_test.shape)\n",
    "save_npz(f'../input/sparse_train_row{sp_train.shape[0]}_feat{sp_train.shape[1]}.npz', sp_train, compressed=True)\n",
    "save_npz(f'../input/sparse_test_row{sp_test.shape[0]}_feat{sp_test.shape[1]}.npz', sp_test, compressed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4968"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del cat_train, num_train\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
