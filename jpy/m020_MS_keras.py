is_debug = 1
import os
import re
import sys
import glob
import datetime
import pandas as pd
import numpy as np
HOME = os.path.expanduser('~')
sys.path.append(f"{HOME}/kaggle/data_analysis/library/")
sys.path.append(f"../py/")
import MS_utils
import utils, ml_utils, kaggle_utils
from utils import logger_func
try:
    if not logger:
        logger=logger_func()
except NameError:
    logger=logger_func()
import time
from sklearn.metrics import roc_auc_score, mean_squared_error

# Columns
key, target, ignore_list = MS_utils.get_basic_var()


from sklearn.metrics import mean_squared_error, roc_auc_score
#========================================================================
# Keras 
# Corporación Favorita Grocery Sales Forecasting
sys.path.append(f'{HOME}/kaggle/data_analysis/model')
from nn_keras import MS_NN
from keras import callbacks
from keras import optimizers
from keras import backend as K
from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
#========================================================================

start_time = "{0:%Y%m%d_%H%M%S}".format(datetime.datetime.now())

base = utils.read_df_pkl('../input/base_group*')[[key, target, 'country_group']]

# feat_path_list = glob.glob('../features/4_winner/*.gz')
train, test = MS_utils.get_dataset(base=base, feat_path='../features/4_winner/*.gz', is_debug=False)
del base
gc.collect()

if is_debug:
    train = train.head(10000)
    test = test.head(500)
    
#========================================================================
# Categorical Encode
cat_cols = utils.get_categorical_features(df=train, ignore_list=ignore_list)
print(f"Categorical: {cat_cols}")

#Fit LabelEncoder
for col in cat_cols:
    # 最も頻度の多いカテゴリでimpute
    max_freq = list(train[col].value_counts().index)[0]
    train[col].fillna(max_freq, inplace=True)
    test[col].fillna(max_freq, inplace=True)
    le = LabelEncoder().fit(pd.concat([train[col], test[col]], axis=0).value_counts().index.tolist())
    train[col] = le.transform(train[col])
    test[col]  = le.transform(test[col])
#========================================================================

#========================================================================
# 正規化の前処理(Null埋め, inf, -infの処理) 
for col in train.columns:
    if col in ignore_list: continue
        
    train[col] = utils.impute_feature(train, col)
    test[col]  = utils.impute_feature(test, col)
#========================================================================

#========================================================================
# 正規化
from sklearn.preprocessing import StandardScaler

train_test = pd.concat([train, test], axis=0)
base_train = train_test[~train_test[target].isnull()]
base_test = train_test[train_test[target].isnull()]

use_cols = [col for col in train.columns if col not in ignore_list]
scaler = StandardScaler()
scaler.fit(train_test[use_cols])
    
train = train_test[~train_test[target].isnull()]
test = train_test[train_test[target].isnull()]

x_test = scaler.transform(test[use_cols])
         
Y = train[target]

print(f"Train: {train.shape} | Test: {test.shape}") 
# ========================================================================

#========================================================================
# CVの準備
seed = 1208
fold_n = 5
kfold = MS_utils.get_kfold(base=base_train)
kfold = zip(*kfold)
#========================================================================