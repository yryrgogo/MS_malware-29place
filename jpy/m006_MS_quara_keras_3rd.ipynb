{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import gc\n",
    "import re\n",
    "import sys\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "HOME = os.path.expanduser('~')\n",
    "sys.path.append(f\"{HOME}/kaggle/data_analysis/library/\")\n",
    "sys.path.append(f\"../py/\")\n",
    "\n",
    "import MS_utils\n",
    "import utils, ml_utils, kaggle_utils\n",
    "from utils import logger_func\n",
    "try:\n",
    "    if not logger:\n",
    "        logger=logger_func()\n",
    "except NameError:\n",
    "    logger=logger_func()\n",
    "    \n",
    "import time\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error\n",
    "\n",
    "# Columns\n",
    "key, target, ignore_list = MS_utils.get_basic_var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, CuDNNLSTM, Embedding, Dropout, Activation, CuDNNGRU, Conv1D\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.layers import Input, Embedding, Dense, Conv2D, MaxPool2D, concatenate\n",
    "from keras.layers import Reshape, Flatten, Concatenate, Dropout, SpatialDropout1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "\n",
    "import sys\n",
    "from os.path import dirname\n",
    "#sys.path.append(dirname(dirname(__file__)))\n",
    "from keras import initializers\n",
    "from keras.engine import InputSpec, Layer\n",
    "from keras import backend as K\n",
    "\n",
    "# import spacy\n",
    "\n",
    "# https://github.com/bfelbo/DeepMoji/blob/master/deepmoji/attlayer.py\n",
    "class AttentionWeightedAverage(Layer):\n",
    "    \"\"\"\n",
    "    Computes a weighted average of the different channels across timesteps.\n",
    "    Uses 1 parameter pr. channel to compute the attention value for a single timestep.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, return_attention=False, **kwargs):\n",
    "        self.init = initializers.get('uniform')\n",
    "        self.supports_masking = True\n",
    "        self.return_attention = return_attention\n",
    "        super(AttentionWeightedAverage, self).__init__(** kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.input_spec = [InputSpec(ndim=3)]\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight(shape=(input_shape[2], 1),\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 initializer=self.init)\n",
    "        self.trainable_weights = [self.W]\n",
    "        super(AttentionWeightedAverage, self).build(input_shape)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        # computes a probability distribution over the timesteps\n",
    "        # uses 'max trick' for numerical stability\n",
    "        # reshape is done to avoid issue with Tensorflow\n",
    "        # and 1-dimensional weights\n",
    "        logits = K.dot(x, self.W)\n",
    "        x_shape = K.shape(x)\n",
    "        logits = K.reshape(logits, (x_shape[0], x_shape[1]))\n",
    "        ai = K.exp(logits - K.max(logits, axis=-1, keepdims=True))\n",
    "\n",
    "        # masked timesteps have zero weight\n",
    "        if mask is not None:\n",
    "            mask = K.cast(mask, K.floatx())\n",
    "            ai = ai * mask\n",
    "        att_weights = ai / (K.sum(ai, axis=1, keepdims=True) + K.epsilon())\n",
    "        weighted_input = x * K.expand_dims(att_weights)\n",
    "        result = K.sum(weighted_input, axis=1)\n",
    "        if self.return_attention:\n",
    "            return [result, att_weights]\n",
    "        return result\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return self.compute_output_shape(input_shape)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        output_len = input_shape[2]\n",
    "        if self.return_attention:\n",
    "            return [(input_shape[0], output_len), (input_shape[0], input_shape[1])]\n",
    "        return (input_shape[0], output_len)\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        if isinstance(input_mask, list):\n",
    "            return [None] * len(input_mask)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "\n",
    "def build_model(nb_words, max_length, embedding_size=300):\n",
    "    inp = Input(shape=(max_length,))\n",
    "#     x = Embedding(nb_words, embedding_size, weights=[embedding_matrix], trainable=False)(inp)\n",
    "    x = Embedding(nb_words, embedding_size, input_length=max_length)(inp)\n",
    "    x = SpatialDropout1D(0.3)(x)\n",
    "    x1 = Bidirectional(CuDNNLSTM(256, return_sequences=True))(x)\n",
    "    x2 = Bidirectional(CuDNNGRU(128, return_sequences=True))(x1)\n",
    "    max_pool1 = GlobalMaxPooling1D()(x1)\n",
    "    max_pool2 = GlobalMaxPooling1D()(x2)\n",
    "    conc = Concatenate()([max_pool1, max_pool2])\n",
    "    predictions = Dense(1, activation='sigmoid')(conc)\n",
    "    model = Model(inputs=inp, outputs=predictions)\n",
    "    adam = optimizers.Adam(lr=learning_rate)\n",
    "    model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "        'MachineIdentifier':                                    'category',\n",
    "        'ProductName':                                          'category',\n",
    "        'EngineVersion':                                        'category',\n",
    "        'AppVersion':                                           'category',\n",
    "        'AvSigVersion':                                         'category',\n",
    "        'IsBeta':                                               'int8',\n",
    "        'RtpStateBitfield':                                     'float16',\n",
    "        'IsSxsPassiveMode':                                     'int8',\n",
    "        'DefaultBrowsersIdentifier':                            'float16',\n",
    "        'AVProductStatesIdentifier':                            'float32',\n",
    "        'AVProductsInstalled':                                  'float16',\n",
    "        'AVProductsEnabled':                                    'float16',\n",
    "        'HasTpm':                                               'int8',\n",
    "        'CountryIdentifier':                                    'int16',\n",
    "        'CityIdentifier':                                       'float32',\n",
    "        'OrganizationIdentifier':                               'float16',\n",
    "        'GeoNameIdentifier':                                    'float16',\n",
    "        'LocaleEnglishNameIdentifier':                          'int8',\n",
    "        'Platform':                                             'category',\n",
    "        'Processor':                                            'category',\n",
    "        'OsVer':                                                'category',\n",
    "        'OsBuild':                                              'int16',\n",
    "        'OsSuite':                                              'int16',\n",
    "        'OsPlatformSubRelease':                                 'category',\n",
    "        'OsBuildLab':                                           'category',\n",
    "        'SkuEdition':                                           'category',\n",
    "        'IsProtected':                                          'float16',\n",
    "        'AutoSampleOptIn':                                      'int8',\n",
    "        'PuaMode':                                              'category',\n",
    "        'SMode':                                                'float16',\n",
    "        'IeVerIdentifier':                                      'float16',\n",
    "        'SmartScreen':                                          'category',\n",
    "        'Firewall':                                             'float16',\n",
    "        'UacLuaenable':                                         'float32',\n",
    "        'Census_MDC2FormFactor':                                'category',\n",
    "        'Census_DeviceFamily':                                  'category',\n",
    "        'Census_OEMNameIdentifier':                             'float16',\n",
    "        'Census_OEMModelIdentifier':                            'float32',\n",
    "        'Census_ProcessorCoreCount':                            'float16',\n",
    "        'Census_ProcessorManufacturerIdentifier':               'float16',\n",
    "        'Census_ProcessorModelIdentifier':                      'float16',\n",
    "        'Census_ProcessorClass':                                'category',\n",
    "        'Census_PrimaryDiskTotalCapacity':                      'float32',\n",
    "        'Census_PrimaryDiskTypeName':                           'category',\n",
    "        'Census_SystemVolumeTotalCapacity':                     'float32',\n",
    "        'Census_HasOpticalDiskDrive':                           'int8',\n",
    "        'Census_TotalPhysicalRAM':                              'float32',\n",
    "        'Census_ChassisTypeName':                               'category',\n",
    "        'Census_InternalPrimaryDiagonalDisplaySizeInInches':    'float16',\n",
    "        'Census_InternalPrimaryDisplayResolutionHorizontal':    'float16',\n",
    "        'Census_InternalPrimaryDisplayResolutionVertical':      'float16',\n",
    "        'Census_PowerPlatformRoleName':                         'category',\n",
    "        'Census_InternalBatteryType':                           'category',\n",
    "        'Census_InternalBatteryNumberOfCharges':                'float32',\n",
    "        'Census_OSVersion':                                     'category',\n",
    "        'Census_OSArchitecture':                                'category',\n",
    "        'Census_OSBranch':                                      'category',\n",
    "        'Census_OSBuildNumber':                                 'int16',\n",
    "        'Census_OSBuildRevision':                               'int32',\n",
    "        'Census_OSEdition':                                     'category',\n",
    "        'Census_OSSkuName':                                     'category',\n",
    "        'Census_OSInstallTypeName':                             'category',\n",
    "        'Census_OSInstallLanguageIdentifier':                   'float16',\n",
    "        'Census_OSUILocaleIdentifier':                          'int16',\n",
    "        'Census_OSWUAutoUpdateOptionsName':                     'category',\n",
    "        'Census_IsPortableOperatingSystem':                     'int8',\n",
    "        'Census_GenuineStateName':                              'category',\n",
    "        'Census_ActivationChannel':                             'category',\n",
    "        'Census_IsFlightingInternal':                           'float16',\n",
    "        'Census_IsFlightsDisabled':                             'float16',\n",
    "        'Census_FlightRing':                                    'category',\n",
    "        'Census_ThresholdOptIn':                                'float16',\n",
    "        'Census_FirmwareManufacturerIdentifier':                'float16',\n",
    "        'Census_FirmwareVersionIdentifier':                     'float32',\n",
    "        'Census_IsSecureBootEnabled':                           'int8',\n",
    "        'Census_IsWIMBootEnabled':                              'float16',\n",
    "        'Census_IsVirtualDevice':                               'float16',\n",
    "        'Census_IsTouchEnabled':                                'int8',\n",
    "        'Census_IsPenCapable':                                  'int8',\n",
    "        'Census_IsAlwaysOnAlwaysConnectedCapable':              'float16',\n",
    "        'Wdft_IsGamer':                                         'float16',\n",
    "        'Wdft_RegionIdentifier':                                'float16',\n",
    "        'HasDetections':                                        'int8'\n",
    "        }\n",
    "\n",
    "print('Download Train and Test Data.\\n')\n",
    "train = pd.read_csv('../input/train.csv', dtype=dtypes, low_memory=True)\n",
    "train['MachineIdentifier'] = train.index.astype('uint32')\n",
    "test  = pd.read_csv('../input/test.csv',  dtype=dtypes, low_memory=True)\n",
    "test['MachineIdentifier']  = test.index.astype('uint32')\n",
    "\n",
    "gc.collect()\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete!!\n"
     ]
    }
   ],
   "source": [
    "nlp_cols = [\n",
    "    'SkuEdition'\n",
    "#     ,'SmartScreen'\n",
    "    ,'EngineVersion'\n",
    "    ,'AppVersion'\n",
    "    ,'AvSigVersion'\n",
    "    ,'Census_OSArchitecture'\n",
    "    ,'AVProductStatesIdentifier'\n",
    "    ,'AVProductsInstalled'\n",
    "    ,'CountryIdentifier'\n",
    "    ,'CityIdentifier'\n",
    "    ,'OrganizationIdentifier'\n",
    "    ,'GeoNameIdentifier'\n",
    "    ,'LocaleEnglishNameIdentifier'\n",
    "    ,'OsBuild'\n",
    "    ,'OsBuildLab'\n",
    "    ,'Census_OSVersion'\n",
    "    ,'Census_OEMNameIdentifier'\n",
    "    ,'Census_OEMModelIdentifier'\n",
    "    ,'Census_ProcessorCoreCount'\n",
    "    ,'Census_ProcessorManufacturerIdentifier' \n",
    "    ,'Census_PrimaryDiskTypeName'\n",
    "    ,'Census_OSBranch'\n",
    "    ,'Census_OSBuildNumber'\n",
    "    ,'Census_OSBuildRevision'\n",
    "    ,'Census_OSEdition'\n",
    "    ,'Census_OSInstallTypeName'\n",
    "    ,'Census_OSInstallLanguageIdentifier'\n",
    "    ,'Census_OSUILocaleIdentifier'\n",
    "    ,'Census_OSWUAutoUpdateOptionsName'\n",
    "    ,'Census_GenuineStateName'\n",
    "    ,'Census_ActivationChannel'\n",
    "    ,'Census_FlightRing'\n",
    "    ,'Census_FirmwareManufacturerIdentifier'\n",
    "    ,'Census_FirmwareVersionIdentifier'\n",
    "]\n",
    "\n",
    "num_list = [\n",
    "    'Census_PrimaryDiskTotalCapacity'\n",
    "    ,'Census_SystemVolumeTotalCapacity'\n",
    "    ,'Census_TotalPhysicalRAM'\n",
    "    ,'Census_InternalPrimaryDiagonalDisplaySizeInInches'\n",
    "    ,'Census_InternalPrimaryDisplayResolutionHorizontal'\n",
    "    ,'Census_InternalPrimaryDisplayResolutionVertical'\n",
    "    ,'Census_InternalBatteryNumberOfCharges'\n",
    "    ,'Wdft_IsGamer'\n",
    "]\n",
    "\n",
    "# Text\n",
    "nlp_train = train[[key, target] + nlp_cols]\n",
    "nlp_test = test[[key] + nlp_cols]\n",
    "\n",
    "# Numeric\n",
    "num_train = train[num_list]\n",
    "num_test = test[num_list]\n",
    "\n",
    "is_debug = 0\n",
    "if is_debug:\n",
    "    nlp_train = nlp_train.head(10000)\n",
    "    nlp_test = nlp_test.head(1000)\n",
    "    num_train = num_train.head(10000)\n",
    "    num_test = num_test.head(1000)\n",
    "\n",
    "nlp_train = pd.concat([nlp_train, nlp_test], axis=0)\n",
    "print(\"Complete!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete!!\n"
     ]
    }
   ],
   "source": [
    "#========================================================================\n",
    "# Engineのversionを分ける\n",
    "#========================================================================\n",
    "\n",
    "en_col = 'EngineVersion'\n",
    "engine = nlp_train[en_col]\n",
    "engine = engine.map(lambda x: x[4:])\n",
    "df_en = pd.DataFrame([en.split('.') for en in engine.values], columns=['Engine-Major', 'Engine-Sub'])\n",
    "col = 'Engine-Major'\n",
    "feature = df_en[col].values.astype('float32')\n",
    "nlp_train[col] = feature\n",
    "# utils.to_pkl_gzip(obj=feature, path=f'../features/1_first_valid/{prefix}_{col}')\n",
    "\n",
    "col = 'Engine-Sub'\n",
    "feature = df_en[col].values.astype('float32')\n",
    "nlp_train[col] = feature\n",
    "\n",
    "del nlp_train[en_col]\n",
    "# utils.to_pkl_gzip(obj=feature, path=f'../features/1_first_valid/{prefix}_{col}')\n",
    "\n",
    "#========================================================================\n",
    "# 'AvSigVersion'のversionを分ける\n",
    "#========================================================================\n",
    "\n",
    "vi_col = 'AvSigVersion'\n",
    "vi = nlp_train[vi_col]\n",
    "vi_pre = vi.map(lambda x: np.int(x[:4].replace('.', '').replace('&', '')))\n",
    "vi_suf = vi.map(lambda x: np.int(x[5:].replace('.', '').replace(\"x17;311440\", '311440')))\n",
    "\n",
    "df_vi = pd.concat([vi_pre, vi_suf], axis=1)\n",
    "df_vi.columns = ['AvSigVersion-Major', 'AvSigVersion-Sub']\n",
    "\n",
    "col = 'AvSigVersion-Major'\n",
    "feature = df_vi[col].values.astype('float32')\n",
    "# utils.to_pkl_gzip(obj=feature, path=f'../features/1_first_valid/{prefix}_{col}')\n",
    "nlp_train[col] = feature\n",
    "\n",
    "col = 'AvSigVersion-Sub'\n",
    "feature = df_vi[col].values.astype('float32')\n",
    "# utils.to_pkl_gzip(obj=feature, path=f'../features/1_first_valid/{prefix}_{col}')\n",
    "\n",
    "nlp_train[col] = feature\n",
    "\n",
    "del nlp_train[vi_col]\n",
    "\n",
    "#========================================================================\n",
    "# OSのversionを分ける\n",
    "#========================================================================\n",
    "\n",
    "os_col = 'Census_OSVersion'\n",
    "os = nlp_train[os_col]\n",
    "os = os.map(lambda x: x.replace('10.0.', ''))\n",
    "\n",
    "os_list = [v.split('.') for v in os.values]\n",
    "df_os = pd.DataFrame(os_list, columns=[\"OSVersion-Major\", \"OSVersion-Sub\", '0', '1'])\n",
    "# df_os = pd.DataFrame(os_list, columns=[\"OSVersion-Major\", \"OSVersion-Sub\"])\n",
    "\n",
    "col = 'OSVersion-Major'\n",
    "feature = df_os[col].values.astype('float32')\n",
    "# utils.to_pkl_gzip(obj=feature, path=f'../features/1_first_valid/{prefix}_{col}')\n",
    "nlp_train[col] = feature\n",
    "\n",
    "col = 'OSVersion-Sub'\n",
    "feature = df_os[col].values.astype('float32')\n",
    "# utils.to_pkl_gzip(obj=feature, path=f'../features/1_first_valid/{prefix}_{col}')\n",
    "nlp_train[col] = feature\n",
    "\n",
    "del nlp_train[os_col]\n",
    "\n",
    "#========================================================================\n",
    "# Appのversionを分ける\n",
    "#========================================================================\n",
    "\n",
    "app_col = 'AppVersion'\n",
    "app = nlp_train[app_col]\n",
    "app = app.map(lambda x: x[2:])\n",
    "\n",
    "app_list = [v.split('.') for v in app.values]\n",
    "df_app = pd.DataFrame(app_list, columns=[\"AppVersion-1\", \"AppVersion-2\", \"AppVersion-3\"])\n",
    "\n",
    "col = 'AppVersion-1'\n",
    "feature = df_app[col].values.astype('float32')\n",
    "# utils.to_pkl_gzip(obj=feature, path=f'../features/1_first_valid/{prefix}_{col}')\n",
    "nlp_train[col] = feature\n",
    "\n",
    "col = 'AppVersion-2'\n",
    "feature = df_app[col].values.astype('float32')\n",
    "# utils.to_pkl_gzip(obj=feature, path=f'../features/1_first_valid/{prefix}_{col}')\n",
    "nlp_train[col] = feature\n",
    "\n",
    "col = 'AppVersion-3'\n",
    "feature = df_app[col].values.astype('float32')\n",
    "# utils.to_pkl_gzip(obj=feature, path=f'../features/1_first_valid/{prefix}_{col}')\n",
    "nlp_train[col] = feature\n",
    "\n",
    "del nlp_train[app_col]\n",
    "print(\"Complete!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_53447</td>\n",
       "      <td>1_1</td>\n",
       "      <td>Retail</td>\n",
       "      <td>3_628</td>\n",
       "      <td>4_36144</td>\n",
       "      <td>Retail</td>\n",
       "      <td>IS_GENUINE</td>\n",
       "      <td>7_9124</td>\n",
       "      <td>8_2668</td>\n",
       "      <td>amd64</td>\n",
       "      <td>...</td>\n",
       "      <td>Pro</td>\n",
       "      <td>31_15100</td>\n",
       "      <td>32_1</td>\n",
       "      <td>33_127</td>\n",
       "      <td>34_17350</td>\n",
       "      <td>35_17134</td>\n",
       "      <td>36_165</td>\n",
       "      <td>37_18</td>\n",
       "      <td>38_1807</td>\n",
       "      <td>39_18075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_53447</td>\n",
       "      <td>1_1</td>\n",
       "      <td>Retail</td>\n",
       "      <td>3_628</td>\n",
       "      <td>4_57858</td>\n",
       "      <td>NOT_SET</td>\n",
       "      <td>OFFLINE</td>\n",
       "      <td>7_91656</td>\n",
       "      <td>8_2668</td>\n",
       "      <td>amd64</td>\n",
       "      <td>...</td>\n",
       "      <td>Pro</td>\n",
       "      <td>31_14600</td>\n",
       "      <td>32_4</td>\n",
       "      <td>33_126</td>\n",
       "      <td>34_480</td>\n",
       "      <td>35_17134</td>\n",
       "      <td>36_1</td>\n",
       "      <td>37_13</td>\n",
       "      <td>38_17134</td>\n",
       "      <td>39_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_53447</td>\n",
       "      <td>1_1</td>\n",
       "      <td>OEM:NONSLP</td>\n",
       "      <td>3_142</td>\n",
       "      <td>4_52682</td>\n",
       "      <td>Retail</td>\n",
       "      <td>IS_GENUINE</td>\n",
       "      <td>7_317701</td>\n",
       "      <td>8_4908</td>\n",
       "      <td>amd64</td>\n",
       "      <td>...</td>\n",
       "      <td>Home</td>\n",
       "      <td>31_15100</td>\n",
       "      <td>32_1</td>\n",
       "      <td>33_127</td>\n",
       "      <td>34_13410</td>\n",
       "      <td>35_17134</td>\n",
       "      <td>36_165</td>\n",
       "      <td>37_18</td>\n",
       "      <td>38_1807</td>\n",
       "      <td>39_18075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_53447</td>\n",
       "      <td>1_1</td>\n",
       "      <td>OEM:NONSLP</td>\n",
       "      <td>3_355</td>\n",
       "      <td>4_20050</td>\n",
       "      <td>Retail</td>\n",
       "      <td>IS_GENUINE</td>\n",
       "      <td>7_275890</td>\n",
       "      <td>8_1443</td>\n",
       "      <td>amd64</td>\n",
       "      <td>...</td>\n",
       "      <td>Pro</td>\n",
       "      <td>31_15100</td>\n",
       "      <td>32_1</td>\n",
       "      <td>33_127</td>\n",
       "      <td>34_15270</td>\n",
       "      <td>35_17134</td>\n",
       "      <td>36_228</td>\n",
       "      <td>37_18</td>\n",
       "      <td>38_1807</td>\n",
       "      <td>39_18075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_53447</td>\n",
       "      <td>1_1</td>\n",
       "      <td>Retail</td>\n",
       "      <td>3_355</td>\n",
       "      <td>4_19844</td>\n",
       "      <td>Retail</td>\n",
       "      <td>IS_GENUINE</td>\n",
       "      <td>7_331929</td>\n",
       "      <td>8_1443</td>\n",
       "      <td>amd64</td>\n",
       "      <td>...</td>\n",
       "      <td>Home</td>\n",
       "      <td>31_15100</td>\n",
       "      <td>32_1</td>\n",
       "      <td>33_127</td>\n",
       "      <td>34_13790</td>\n",
       "      <td>35_17134</td>\n",
       "      <td>36_191</td>\n",
       "      <td>37_18</td>\n",
       "      <td>38_1807</td>\n",
       "      <td>39_18075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1           2      3        4        5           6         7  \\\n",
       "0  0_53447  1_1      Retail  3_628  4_36144   Retail  IS_GENUINE    7_9124   \n",
       "1  0_53447  1_1      Retail  3_628  4_57858  NOT_SET     OFFLINE   7_91656   \n",
       "2  0_53447  1_1  OEM:NONSLP  3_142  4_52682   Retail  IS_GENUINE  7_317701   \n",
       "3  0_53447  1_1  OEM:NONSLP  3_355  4_20050   Retail  IS_GENUINE  7_275890   \n",
       "4  0_53447  1_1      Retail  3_355  4_19844   Retail  IS_GENUINE  7_331929   \n",
       "\n",
       "        8      9    ...       30        31    32      33        34        35  \\\n",
       "0  8_2668  amd64    ...      Pro  31_15100  32_1  33_127  34_17350  35_17134   \n",
       "1  8_2668  amd64    ...      Pro  31_14600  32_4  33_126    34_480  35_17134   \n",
       "2  8_4908  amd64    ...     Home  31_15100  32_1  33_127  34_13410  35_17134   \n",
       "3  8_1443  amd64    ...      Pro  31_15100  32_1  33_127  34_15270  35_17134   \n",
       "4  8_1443  amd64    ...     Home  31_15100  32_1  33_127  34_13790  35_17134   \n",
       "\n",
       "       36     37        38        39  \n",
       "0  36_165  37_18   38_1807  39_18075  \n",
       "1    36_1  37_13  38_17134      39_1  \n",
       "2  36_165  37_18   38_1807  39_18075  \n",
       "3  36_228  37_18   38_1807  39_18075  \n",
       "4  36_191  37_18   38_1807  39_18075  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#========================================================================\n",
    "# Cleansing\n",
    "\n",
    "new_cols = [col  if col in ignore_list else str(num) for num, col in enumerate(nlp_train.columns)]\n",
    "nlp_train.columns = new_cols\n",
    "\n",
    "nlp_dtype_dict = nlp_train.dtypes\n",
    "for col in nlp_train.columns:\n",
    "    if col in ignore_list:\n",
    "        continue\n",
    "        \n",
    "    mode = nlp_train[col].mode().values[0]\n",
    "\n",
    "    nlp_train[col].fillna(mode, inplace=True)\n",
    "    \n",
    "    if str(nlp_dtype_dict[col]).count('int') or str(nlp_dtype_dict[col]).count('float'):\n",
    "        nlp_train[col] = nlp_train[col].map(lambda x: col + '_' + str(int(x)))\n",
    "        \n",
    "nlp_train.head()\n",
    "#========================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data ...\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-206-ea13fb7eb5b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtx_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"text\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# nlp_train[tx_col] = nlp_train[use_cols].apply(lambda x: ' '.join([ str(tx) for tx in x]), axis=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mnlp_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtx_col\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muse_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mtext_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtx_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2131\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2132\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2133\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2134\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2135\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2176\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2177\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2178\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_take\u001b[0;34m(self, indices, axis, convert, is_copy)\u001b[0m\n\u001b[1;32m   2141\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_shared_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_take'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2142\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_copy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2143\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3675\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3677\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3679\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_protect_consolidate\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m   3664\u001b[0m         \"\"\"\n\u001b[1;32m   3665\u001b[0m         \u001b[0mblocks_before\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3666\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3667\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mblocks_before\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3668\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mf\u001b[0;34m()\u001b[0m\n\u001b[1;32m   3673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3674\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3675\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3677\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mconsolidate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3824\u001b[0m         \u001b[0mbm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3825\u001b[0m         \u001b[0mbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3826\u001b[0;31m         \u001b[0mbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3827\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3829\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3830\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_consolidated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3831\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3832\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3833\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_known_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m_consolidate\u001b[0;34m(blocks)\u001b[0m\n\u001b[1;32m   4851\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_can_consolidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_blocks\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrouper\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4852\u001b[0m         merged_blocks = _merge_blocks(list(group_blocks), dtype=dtype,\n\u001b[0;32m-> 4853\u001b[0;31m                                       _can_consolidate=_can_consolidate)\n\u001b[0m\u001b[1;32m   4854\u001b[0m         \u001b[0mnew_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_blocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4855\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_blocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m_merge_blocks\u001b[0;34m(blocks, dtype, _can_consolidate)\u001b[0m\n\u001b[1;32m   4874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4875\u001b[0m         \u001b[0margsort\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_mgr_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4876\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4877\u001b[0m         \u001b[0mnew_mgr_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_mgr_locs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "print(\"Loading data ...\")\n",
    "\n",
    "## Tokenize the sentences\n",
    "use_cols = [col for col in nlp_train.columns if col not in ignore_list]\n",
    "tx_col = \"text\"\n",
    "# nlp_train[tx_col] = nlp_train[use_cols].apply(lambda x: ' '.join([ str(tx) for tx in x]), axis=1)\n",
    "nlp_train[tx_col] = nlp_train[use_cols].apply(lambda x: ' '.join(x.values.tolist()), axis=1)\n",
    "text_list = nlp_train[tx_col].values.tolist()\n",
    "\n",
    "max_features = 10000\n",
    "nb_words = max_features\n",
    "max_length = 100\n",
    "tokenizer = Tokenizer(num_words=max_features, split=\" \")\n",
    "tokenizer.fit_on_texts(text_list)\n",
    "del text_list\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_test = nlp_train[nlp_train[target].isnull()]\n",
    "nlp_train = nlp_train[~nlp_train[target].isnull()]\n",
    "y = nlp_train[target].values\n",
    "nlp_train = nlp_train[tx_col]\n",
    "nlp_test = nlp_test[tx_col]\n",
    "num_train_data = y.shape[0]\n",
    "\n",
    "x_train = tokenizer.texts_to_sequences(nlp_train)\n",
    "x_test = tokenizer.texts_to_sequences(nlp_test)\n",
    "\n",
    "## Pad the sentences \n",
    "train_word_sequences = pad_sequences(x_train, maxlen=maxlen)\n",
    "test_word_sequences = pad_sequences(x_test, maxlen=maxlen)\n",
    "\n",
    "# train_word_sequences = word_sequences[:num_train_data]\n",
    "# test_word_sequences = word_sequences[num_train_data:]\n",
    "\n",
    "train_word_sequences = pad_sequences(train_word_sequences, maxlen=max_length, padding='post')\n",
    "test_word_sequences = pad_sequences(test_word_sequences, maxlen=max_length, padding='post')\n",
    "pred_prob = np.zeros((len(test_word_sequences),), dtype=np.float32)\n",
    "\n",
    "#========================================================================\n",
    "# Numericの結合\n",
    "is_num = 1\n",
    "if is_num:\n",
    "    train_word_sequences = np.hstack((train_word_sequences, num_train.values))\n",
    "    test_word_sequences = np.hstack((test_word_sequences, num_test.values))\n",
    "\n",
    "print(f\"Train: {train_word_sequences.shape} | Test: {test_word_sequences.shape}\")\n",
    "print(train_word_sequences[:1])\n",
    "print(test_word_sequences[:1])\n",
    "#========================================================================\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training ...\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.6921 - acc: 0.5134\n",
      "Epoch 1/2\n",
      " - 9s - loss: 0.6825 - acc: 0.5755\n",
      "Epoch 2/2\n",
      " - 9s - loss: 0.6622 - acc: 0.6036\n",
      "Test Prob Shape: (1000,)\n",
      "--- 29.912076950073242 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "embedding_size = 200\n",
    "learning_rate = 0.001\n",
    "batch_size = 512\n",
    "num_epoch = 8\n",
    "max_length = train_word_sequences.shape[1]\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"Start training ...\")\n",
    "model = build_model(max_length=max_length, nb_words=nb_words, embedding_size=embedding_size)\n",
    "model.fit(train_word_sequences, y, batch_size=batch_size, epochs=num_epoch-1, verbose=2)\n",
    "pred_prob += 0.3*np.squeeze(model.predict(test_word_sequences, batch_size=batch_size, verbose=2))\n",
    "model.fit(train_word_sequences, y, batch_size=batch_size, epochs=2, verbose=2)\n",
    "pred_prob += 0.7*np.squeeze(model.predict(test_word_sequences, batch_size=batch_size, verbose=2))\n",
    "print(f\"Test Prob Shape: {pred_prob.shape}\")\n",
    "del model\n",
    "gc.collect()\n",
    "K.clear_session()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame.from_dict({key: test[key]})\n",
    "submission['prediction'] = (pred_prob>0.35).astype(int)\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
